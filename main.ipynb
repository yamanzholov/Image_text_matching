{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import caption\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import skimage.transform\n",
    "import argparse\n",
    "from scipy.misc import imread, imresize\n",
    "from PIL import Image\n",
    "from encoder import Encoder\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 23:19:03.883181 140330106455872 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "myenc = Encoder()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_flipped_images(directory):\n",
    "    for j in range(1,7):\n",
    "        filename = directory + \"/\" + str(j) + \".jpg\"\n",
    "        img = cv2.imread(filename)\n",
    "        both_img = img.copy()\n",
    "        both_img = cv2.flip( img, -1 )\n",
    "        cv2.imwrite(directory + \"/\" + str(j) + \"_flipped.jpg\" ,both_img)\n",
    "    return 0\n",
    "\n",
    "def generate_blurred_images(directory):\n",
    "    for j in range(1, 7):\n",
    "        filename = directory + \"/\" + str(j) + \".jpg\"\n",
    "        img = cv2.imread(filename)\n",
    "        blurred_image = img.copy()\n",
    "        blurred_image = cv2.blur(img, (20, 20))\n",
    "        cv2.imwrite(directory + \"/\" + str(j) + \"_blurred.jpg\" ,blurred_image)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(raw, stem=False):\n",
    "    \n",
    "    f = open(\"./stop.txt\", 'r')\n",
    "    stop = f.read().split('\\n')\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    stopWords |= set(stop)\n",
    "    \n",
    "    def stem_filter(sentence):\n",
    "            return \" \".join(wordnet_lemmatizer.lemmatize(word.lower(), pos='v') for word in word_tokenize(sentence) if word.lower() not in stopWords)\n",
    "\n",
    "    def tagged_filter(sentence):\n",
    "            tagged_sent = nltk.pos_tag(word_tokenize(sentence))\n",
    "            selected = ['CD', 'FW', 'JJ', 'NN', 'NNP', 'NNS', 'NNPS', 'VBG']\n",
    "            return \" \".join([word[0] for word in tagged_sent if word[1] in selected])\n",
    "    \n",
    "    return stem_filter(raw) if stem else tagged_filter(raw)\n",
    "\n",
    "def directory_to_sentence_matrix_clear(directory):\n",
    "    sentence_dict = {}\n",
    "    for j in range(1,7):\n",
    "        filename = directory + \"/\" + str(j) + \".jpg\"\n",
    "        checkpoint = torch.load('/home/yerlan/HackNU/Jarvis/BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar')\n",
    "        decoder = checkpoint['decoder']\n",
    "        decoder = decoder.to(device)\n",
    "        decoder.eval()\n",
    "        encoder = checkpoint['encoder']\n",
    "        encoder = encoder.to(device)\n",
    "        encoder.eval()\n",
    "\n",
    "        # Load word map (word2ix)\n",
    "        with open('/home/yerlan/HackNU/Jarvis/WORDMAP_coco_5_cap_per_img_5_min_word_freq.json' , 'r') as t:\n",
    "            word_map = json.load(t)\n",
    "        rev_word_map = {v: k for k, v in word_map.items()}  # ix2word\n",
    "\n",
    "\n",
    "        sentence_array = []\n",
    "        # Encode, decode with attention and beam search\n",
    "        for i in range(1, 6):\n",
    "            seq, alphas = caption.caption_image_beam_search(encoder, decoder, filename, word_map, i)\n",
    "            alphas = torch.FloatTensor(alphas)\n",
    "\n",
    "            # Visualize caption and attention of best sequence\n",
    "            sentence_array.append(clear(caption.return_sentence(filename, seq, alphas, rev_word_map)))\n",
    "        sentence_dict[j] = sentence_array\n",
    "\n",
    "    return sentence_dict\n",
    "\n",
    "def directory_to_sentence_matrix_clear_flipped(directory):\n",
    "    sentence_dict = {}\n",
    "    for j in range(1,7):\n",
    "        filename = directory + \"/\" + str(j) + \"_flipped.jpg\"\n",
    "        checkpoint = torch.load('/home/yerlan/HackNU/Jarvis/BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar')\n",
    "        decoder = checkpoint['decoder']\n",
    "        decoder = decoder.to(device)\n",
    "        decoder.eval()\n",
    "        encoder = checkpoint['encoder']\n",
    "        encoder = encoder.to(device)\n",
    "        encoder.eval()\n",
    "\n",
    "        # Load word map (word2ix)\n",
    "        with open('/home/yerlan/HackNU/Jarvis/WORDMAP_coco_5_cap_per_img_5_min_word_freq.json' , 'r') as t:\n",
    "            word_map = json.load(t)\n",
    "        rev_word_map = {v: k for k, v in word_map.items()}  # ix2word\n",
    "\n",
    "\n",
    "        sentence_array = []\n",
    "        # Encode, decode with attention and beam search\n",
    "        for i in range(1, 6):\n",
    "            seq, alphas = caption.caption_image_beam_search(encoder, decoder, filename, word_map, i)\n",
    "            alphas = torch.FloatTensor(alphas)\n",
    "\n",
    "            # Visualize caption and attention of best sequence\n",
    "            sentence_array.append(clear(caption.return_sentence(filename, seq, alphas, rev_word_map)))\n",
    "        sentence_dict[j] = sentence_array\n",
    "\n",
    "    return sentence_dict\n",
    "\n",
    "def directory_to_sentence_matrix_clear_blurred(directory):\n",
    "    sentence_dict = {}\n",
    "    for j in range(1,7):\n",
    "        filename = directory + \"/\" + str(j) + \"_blurred.jpg\"\n",
    "        checkpoint = torch.load('/home/yerlan/HackNU/Jarvis/BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar')\n",
    "        decoder = checkpoint['decoder']\n",
    "        decoder = decoder.to(device)\n",
    "        decoder.eval()\n",
    "        encoder = checkpoint['encoder']\n",
    "        encoder = encoder.to(device)\n",
    "        encoder.eval()\n",
    "\n",
    "        # Load word map (word2ix)\n",
    "        with open('/home/yerlan/HackNU/Jarvis/WORDMAP_coco_5_cap_per_img_5_min_word_freq.json' , 'r') as t:\n",
    "            word_map = json.load(t)\n",
    "        rev_word_map = {v: k for k, v in word_map.items()}  # ix2word\n",
    "\n",
    "\n",
    "        sentence_array = []\n",
    "        # Encode, decode with attention and beam search\n",
    "        for i in range(1, 6):\n",
    "            seq, alphas = caption.caption_image_beam_search(encoder, decoder, filename, word_map, i)\n",
    "            alphas = torch.FloatTensor(alphas)\n",
    "\n",
    "            # Visualize caption and attention of best sequence\n",
    "            sentence_array.append(clear(caption.return_sentence(filename, seq, alphas, rev_word_map)))\n",
    "        sentence_dict[j] = sentence_array\n",
    "\n",
    "    return sentence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_matrix(generated_matrix_of_sentences, given_sentence):\n",
    "    #For generating matrix of cosine similarities\n",
    "    #myenc = Encoder()\n",
    "    emgiven = myenc.encode(given_sentence)\n",
    "    res = []\n",
    "    for i in range(len(generated_matrix_of_sentences)):\n",
    "        emgenerated = myenc.encode(generated_matrix_of_sentences[i])\n",
    "        a = myenc.cosine_similarity(emgiven, emgenerated)[0][0]\n",
    "        res.append(a)\n",
    "        \n",
    "        #For getting the average of the matrix\n",
    "        res_np = np.array(res)\n",
    "        mean = np.mean(res_np)\n",
    "        minimum = np.min(res_np)\n",
    "        \n",
    "    return mean, minimum\n",
    "\n",
    "\n",
    "def read_file(directory):\n",
    "    with open(directory) as file:\n",
    "        text = file.read()\n",
    "        sentence = text.translate({ord(i):None for i in '.!@#$?]}{[,\\n'}) #remove all unnecessary elements\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'models.Encoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'models.DecoderWithAttention' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'models.Attention' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Softmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTMCell' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/yerlan/anaconda3/envs/deeplearning/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Sigmoid' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "6 6\n",
      "3 3\n",
      "4 4\n",
      "6 1\n",
      "5 \n",
      "3 3\n",
      "5 3\n",
      "3 3\n",
      "1 1\n",
      "1 2\n",
      "3 4\n",
      "3 3\n",
      "3 3\n",
      "1 1\n",
      "6 6\n",
      "3 3\n",
      "5 5\n",
      "5 2\n",
      "3 3\n",
      "6 1\n",
      "2 3\n",
      "2 2\n",
      "3 2\n",
      "1 2\n",
      "60.0\n",
      "CPU times: user 9min 53s, sys: 1min 14s, total: 11min 7s\n",
      "Wall time: 6min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "N = 26\n",
    "for i in range(1, N):\n",
    "    path = \"/home/yerlan/HackNU/Jarvis/images/\"\n",
    "    sentence_matrix = []\n",
    "    directory = path + str(i)\n",
    "    # remove after first run\n",
    "#     generate_flipped_images(directory)\n",
    "#     generate_blurred_images(directory)\n",
    "    sentence_dictionary_clear = directory_to_sentence_matrix_clear(directory)\n",
    "#     sentence_dictionary_clear_flipped = directory_to_sentence_matrix_clear_flipped(directory)\n",
    "#     sentence_dictionary_clear_blurred = directory_to_sentence_matrix_clear_blurred(directory)\n",
    "\n",
    "    sent_dir = directory + \"/input\"\n",
    "    orig_sent = read_file(sent_dir)\n",
    "    res = []\n",
    "    for k in range(len(sentence_dictionary_clear)):\n",
    "        cos = cos_matrix(sentence_dictionary_clear[k+1], orig_sent)\n",
    "        res.append((str(k + 1), cos[0]))\n",
    "#     for k in range(len(sentence_dictionary_clear_flipped)):\n",
    "#         cos_flipped = cos_matrix(sentence_dictionary_clear_flipped[k + 1], orig_sent)\n",
    "#         res.append((str(k + 7), cos_flipped[0]))\n",
    "#     for k in range(len(sentence_dictionary_clear_blurred)):\n",
    "#         cos_blurred = cos_matrix(sentence_dictionary_clear_blurred[k + 1], orig_sent)\n",
    "#         res.append((str(k + 13), cos_blurred[0]))\n",
    "\n",
    "    label = sorted(res, key=lambda p: p[1])[0][0]\n",
    "    while(int(label) > 6):\n",
    "        label = str(int(label) - 6)\n",
    "    output = directory + \"/output\"\n",
    "    f = open(output, 'r')\n",
    "    true_label = f.read().strip()\n",
    "    print(label, true_label)\n",
    "    if(label == true_label):\n",
    "        count += 1\n",
    "        \n",
    "accuracy = (float(count) / (N - 1)) * 100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
